{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "!pip install inquirer\n",
    "import inquirer\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%autosave 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SparkFactory:\n",
    "    def __init__(self):\n",
    "        self.source_dataset_folder = Path('./dataset/')\n",
    "        self.spark = SparkSession.builder.appName(__name__).getOrCreate()\n",
    "    \n",
    "    def validate_available_dataset(self):\n",
    "        return [name for name in glob.glob(f'{self.source_dataset_folder}/**/*.csv')]\n",
    "\n",
    "    def read_dataset(self, dataset):\n",
    "        \"\"\"Read source dataset with sql interface\"\"\"\n",
    "        try:\n",
    "            self.spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(self.source_dataset_fodler) \n",
    "            data = self.spark.read.option(\"header\", \"true\").csv(SOURCE_DATASET_FOLDER)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "        return data\n",
    "            \n",
    "    def run(self):\n",
    "        # validate and choose dataset to work with\n",
    "        assert input('Hi! Would u like to see available datasets to process? Y/n: ') == 'Y', 'Okay, see u later!'    \n",
    "        print(self.validate_available_dataset())\n",
    "        dataset = input('Good! Choose one of datasets to work with pasting full path shown in previous step: ')\n",
    "        \n",
    "        while False:\n",
    "            assert Path(dataset).is_file() == True, 'Wrong path, try one more time!'\n",
    "        print(f'Nice, we gonna to preprocess {dataset}')\n",
    "        \n",
    "        # validate and choose method to use\n",
    "        print('Available methods to apply: [A, B, C, D]')\n",
    "        method = input('Now choose one of methods to apply ')\n",
    "        print(method)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SparkFactory().run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inquirer\n",
      "  Downloading inquirer-2.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: python-editor==1.0.4 in /opt/conda/lib/python3.8/site-packages (from inquirer) (1.0.4)\n",
      "Collecting blessed==1.17.6\n",
      "  Downloading blessed-1.17.6-py2.py3-none-any.whl (76 kB)\n",
      "\u001B[K     |████████████████████████████████| 76 kB 1.9 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.8/site-packages (from blessed==1.17.6->inquirer) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from blessed==1.17.6->inquirer) (1.15.0)\n",
      "Collecting readchar==2.0.1\n",
      "  Downloading readchar-2.0.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: readchar, blessed, inquirer\n",
      "Successfully installed blessed-1.17.6 inquirer-2.7.0 readchar-2.0.1\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkFactory:\n",
    "    def __init__(self):\n",
    "        self.source_dataset_folder = Path('./dataset/')\n",
    "        self.spark = SparkSession.builder.appName(__name__).getOrCreate()\n",
    "    \n",
    "    def validate_available_dataset(self):\n",
    "        return [name for name in glob.glob(f'{self.source_dataset_folder}/**/*.csv')]\n",
    "\n",
    "    def read_dataset(self, dataset):\n",
    "        \"\"\"Read source dataset with sql interface\"\"\"\n",
    "        try:\n",
    "            self.spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(self.source_dataset_fodler) \n",
    "            data = self.spark.read.option(\"header\", \"true\").csv(SOURCE_DATASET_FOLDER)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "        return data\n",
    "            \n",
    "    def run(self):\n",
    "        # validate and choose dataset to work with\n",
    "        assert input('Hi! Would u like to see available datasets to process? Y/n: ') == 'Y', 'Okay, see u later!'    \n",
    "        print(self.validate_available_dataset())\n",
    "        dataset = input('Good! Choose one of datasets to work with pasting full path shown in previous step: ')\n",
    "        \n",
    "        while False:\n",
    "            assert Path(dataset).is_file() == True, 'Wrong path, try one more time!'\n",
    "        print(f'Nice, we gonna to preprocess {dataset}')\n",
    "        \n",
    "        # validate and choose method to use\n",
    "        print('Available methods to apply: [A, B, C, D]')\n",
    "        method = input('Now choose one of methods to apply ')\n",
    "        print(method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! Would u like to see available datasets to process? Y/n: Y\n",
      "['dataset/CICIDS2017_fine/X_train.csv', 'dataset/CICIDS2017_top/X_train.csv']\n",
      "Good! Choose one of datasets to work with pasting full path shown in previous step: dataset/CICIDS2017_fine/X_train.csv\n",
      "Nice, we gonna to preprocess dataset/CICIDS2017_fine/X_train.csv\n",
      "Available methods to apply: [A, B, C, D]\n",
      "Now choose one of methods to apply A\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "SparkFactory().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}